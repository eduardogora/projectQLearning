# README.md

## Juego de Laberinto con Q-Learning

Este proyecto es un juego de laberinto implementado en Python utilizando la biblioteca `pygame`. El objetivo del juego es que un agente (representado por un bloque) recorra el laberinto y coloree todas las celdas de camino (`ROAD`) sin chocar con los muros (`WALL`). El agente utiliza el algoritmo de **Q-learning** para aprender a moverse de manera 칩ptima en el laberinto.

---

## Requisitos

Para ejecutar este proyecto, necesitas tener instalado lo siguiente:

- **Python 3.x**: Aseg칰rate de tener Python instalado en tu sistema.
- **Pygame**: La biblioteca `pygame` se utiliza para la interfaz gr치fica del juego.
- **NumPy**: Se utiliza para manejar matrices y operaciones num칠ricas.
- **Matplotlib**: Se utiliza para graficar el historial de 칠xito del agente.

Puedes instalar las dependencias necesarias ejecutando el siguiente comando:

```bash
pip install pygame numpy matplotlib
```

---

## Estructura del Proyecto

El proyecto consta de los siguientes archivos:

1. **`game.py`**: El archivo principal que contiene la l칩gica del juego y el algoritmo de Q-learning.
2. **`easyMazes.py`**: Contiene los laberintos f치ciles y las posiciones iniciales del agente.
3. **`mediumMazes.py`**: Contiene los laberintos de dificultad media y las posiciones iniciales del agente.
4. **`gameconfig.json`**: Archivo de configuraci칩n que define par치metros como el n칰mero m치ximo de pasos, episodios, y si se deben cargar pesos preentrenados.
5. **`Qlearning.json`**: Archivo de configuraci칩n que define los par치metros del algoritmo Q-learning, como la tasa de aprendizaje, el factor de descuento y la exploraci칩n (epsilon).

---

## Configuraci칩n

### Archivo `gameconfig.json`

Este archivo contiene los siguientes par치metros:

- **`fps`**: Los fotogramas por segundo del juego.
- **`max_steps`**: El n칰mero m치ximo de pasos permitidos por episodio.
- **`max_episodes`**: El n칰mero m치ximo de episodios de entrenamiento.
- **`size`**: El tama침o de la Q-table (depende del tama침o del laberinto).
- **`load_weights`**: Si es `true`, el juego cargar치 una Q-table previamente entrenada desde `Checkpoints/Q_table.npy`. Si es `false`, comenzar치 con una Q-table vac칤a.
- **`enable_render`**: Si es `true`, se habilitar치 la renderizaci칩n gr치fica del juego. Si es `false`, el juego se ejecutar치 en modo "headless" (sin interfaz gr치fica).

### Archivo `Qlearning.json`

Este archivo contiene los siguientes par치metros del algoritmo Q-learning:

- **`max_epsilon`**: El valor m치ximo de epsilon (exploraci칩n).
- **`min_epsilon`**: El valor m칤nimo de epsilon.
- **`epsilon_decay`**: La tasa de decaimiento de epsilon.
- **`learning_rate`**: La tasa de aprendizaje del algoritmo.
- **`discount_factor`**: El factor de descuento para las recompensas futuras.
- **`epsilon`**: El valor inicial de epsilon.

---

## Ejecuci칩n del Juego

Para ejecutar el juego, sigue estos pasos:

1. **Clona el repositorio** o descarga los archivos del proyecto.
2. **Navega al directorio** donde se encuentran los archivos.
3. **Ejecuta el archivo `game.py`**:

```bash
python game.py
```

### Modo de Entrenamiento

- Si `load_weights` es `false` en `gameconfig.json`, el juego comenzar치 con una Q-table vac칤a y entrenar치 al agente desde cero.
- Al final del entrenamiento, la Q-table se guardar치 en `Checkpoints/Q_table.npy`.

### Modo de Prueba

- Si `load_weights` es `true`, el juego cargar치 la Q-table previamente entrenada desde `Checkpoints/Q_table.npy` y la utilizar치 para tomar decisiones.

---

## Resultados

Al finalizar el entrenamiento, el juego mostrar치:

1. **Gr치fico de 칠xito**: Un gr치fico que muestra el n칰mero de pasos necesarios para completar cada episodio.
2. **Q-table**: La tabla Q final se imprimir치 en la consola.
3. **N칰mero de victorias**: El n칰mero de veces que el agente complet칩 el laberinto correctamente.

---

## Personalizaci칩n

### Laberintos

Puedes agregar o modificar laberintos en los archivos `easyMazes.py` y `mediumMazes.py`. Cada laberinto es una matriz donde:

- `0` representa un muro (`WALL`).
- `2` representa un camino (`ROAD`).
- `1` representa la posici칩n inicial del agente (`PLAYER`).

### Par치metros de Q-learning

Puedes ajustar los par치metros del algoritmo Q-learning en el archivo `Qlearning.json` para mejorar el rendimiento del agente.

---

## Ejemplo de Laberinto

Aqu칤 hay un ejemplo de un laberinto en `easyMazes.py`:

```python
grids = [
    np.array([
        [0, 0, 0, 0, 0],
        [0, 2, 2, 0, 0],
        [0, 0, 2, 2, 0],
        [0, 0, 0, 2, 0],
        [0, 0, 0, 0, 0],
    ]),
]
```

---

## Contribuciones

Si deseas contribuir a este proyecto, 춰eres bienvenido! Puedes:

- Agregar nuevos laberintos.
- Mejorar el algoritmo de Q-learning.
- Optimizar el c칩digo o agregar nuevas caracter칤sticas.

---

## Licencia

Este proyecto est치 bajo la licencia MIT. Si칠ntete libre de usarlo y modificarlo seg칰n tus necesidades.

---

춰Gracias por usar este proyecto! Si tienes alguna pregunta o sugerencia, no dudes en contactarme. 游땕

---

